
[get][html][page] with [urllib][requests][dryscrape][selenium].txt

========

According to what you need, here are the pip3 commands
    sudo pip3 install dryscrape
    sudo pip3 install requests
    sudo pip3 install scrapy
    sudo pip3 install selenium


In 01_urllib_vs_requests.py:
    We show that the formatting from requests is superior to the one from urllib.
    requests is actually an abstraction over urllib3
    It provides a number of improvements listed here: http://docs.python-requests.org/en/master/
    There may be yet another option with
        - httplib2: http://stackoverflow.com/a/646213
        - pycurl: http://pycurl.io/


In 02_requests_vs_dryscrape.py:
    We show that requests does not execute javascript but dryscrape does.
    The source was this stackoverflow answer: http://stackoverflow.com/a/26440563


There are other ways to execute javascript from the python request with selenium:
    https://selenium-python.readthedocs.io/
    Different drivers can be used. Here is the complete list:
        https://selenium-python.readthedocs.io/api.html
    For instance, we can run:
        | webdriver.Chrome()
            which opens a chrome browser
        | webdriver.Firefox()
            In this case geckodriver needs to be installed, otherwise we get the error:
            | FileNotFoundError: [Errno 2] No such file or directory: geckodriver
        | webdriver.PhantomJS()
            In this case PhantomJS need to be installed first
            Which is the best option if we don't want to open a browser
            Source: http://stackoverflow.com/a/23898028


Finally, Scrapy may also be an option:
    https://doc.scrapy.org/en/latest/intro/tutorial.html
